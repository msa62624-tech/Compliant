name: Performance Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
  schedule:
    # Run performance tests weekly on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'

jobs:
  performance-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: compliant_perf_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 8.15.0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install k6 for load testing
        run: |
          # Use GitHub's prebuilt k6 binary for more reliable installation
          curl -L https://github.com/grafana/k6/releases/download/v0.49.0/k6-v0.49.0-linux-amd64.tar.gz | tar xvz
          sudo mv k6-v0.49.0-linux-amd64/k6 /usr/local/bin/
          k6 version

      - name: Build packages
        run: |
          cd packages/shared && pnpm build
          cd ../backend && pnpm db:generate && pnpm build
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/compliant_perf_test

      - name: Run migrations and seed
        run: |
          cd packages/backend
          pnpm prisma db push
          pnpm db:seed || echo "Seed script not available"
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/compliant_perf_test
          NODE_ENV: test
        continue-on-error: true

      - name: Start backend server
        run: |
          cd packages/backend
          NODE_ENV=production pnpm start:prod > backend.log 2>&1 &
          echo $! > backend.pid
          # Wait for backend using liveness probe
          echo "Waiting for backend to start..."
          timeout 60 bash -c 'until curl -f -H "X-API-Version: 1" http://localhost:3001/api/health/liveness 2>/dev/null; do sleep 2; done' || {
            echo "Backend failed to start. Logs:"
            cat backend.log
            exit 1
          }
          echo "Backend started successfully"
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/compliant_perf_test
          REDIS_URL: redis://localhost:6379
          JWT_SECRET: test-jwt-secret-key-for-performance-tests-32chars
          JWT_REFRESH_SECRET: test-jwt-refresh-secret-key-performance-tests
          ENCRYPTION_KEY: dGVzdC1lbmNyeXB0aW9uLWtleS1mb3ItcGVyZm9ybWFuY2UtdGVzdHMxMg==
          ENCRYPTION_SALT: 0123456789abcdef0123456789abcdef
          SMTP_USER: test-perf@example.com
          SMTP_PASS: test-password-for-performance-tests
          NODE_ENV: production
          PORT: 3001

      - name: Create k6 load test script
        run: |
          mkdir -p k6-tests
          cat > k6-tests/load-test.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate } from 'k6/metrics';
          import { textSummary } from 'https://jslib.k6.io/k6-summary/0.0.1/index.js';
          
          const errorRate = new Rate('errors');
          const BASE_URL = 'http://localhost:3001';
          
          export const options = {
            stages: [
              { duration: '30s', target: 10 },   // Ramp-up to 10 users
              { duration: '1m', target: 50 },    // Ramp-up to 50 users
              { duration: '2m', target: 50 },    // Stay at 50 users
              { duration: '30s', target: 100 },  // Spike to 100 users
              { duration: '1m', target: 100 },   // Stay at 100 users
              { duration: '30s', target: 0 },    // Ramp-down to 0 users
            ],
            thresholds: {
              'http_req_duration': ['p(95)<500', 'p(99)<1000'], // 95% < 500ms, 99% < 1s
              'http_req_failed': ['rate<0.05'],                  // Error rate < 5%
              'errors': ['rate<0.05'],
            },
          };
          
          export default function () {
            // Test liveness endpoint (simpler, faster)
            let livenessRes = http.get(`${BASE_URL}/api/health/liveness`);
            let livenessCheck = check(livenessRes, {
              'liveness check status is 200': (r) => r.status === 200,
              'liveness check response time < 100ms': (r) => r.timings.duration < 100,
            });
            errorRate.add(!livenessCheck);
            
            sleep(1);
            
            // Test full health endpoint
            let healthRes = http.get(`${BASE_URL}/api/health`);
            let healthCheck = check(healthRes, {
              'health check status is 200': (r) => r.status === 200,
              'health check response time < 500ms': (r) => r.timings.duration < 500,
            });
            errorRate.add(!healthCheck);
            
            sleep(1);
          }
          
          export function handleSummary(data) {
            return {
              'k6-results.json': JSON.stringify(data),
              'stdout': textSummary(data, { indent: ' ', enableColors: true }),
            };
          }
          EOF

      - name: Run k6 load test
        run: |
          k6 run k6-tests/load-test.js --out json=k6-results.json
        continue-on-error: true

      - name: Run Lighthouse performance audit
        run: |
          echo "Skipping Lighthouse CI for API-only backend"
          echo "Lighthouse is designed for web pages, not API endpoints"
          echo "Performance metrics are covered by k6 load tests"
        continue-on-error: true

      - name: Analyze performance metrics
        run: |
          if [ -f k6-results.json ]; then
            echo "## âš¡ Performance Test Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### K6 Load Test Summary" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Extract key metrics using jq
            HTTP_REQ_DURATION_P95=$(jq -r '.metrics.http_req_duration.values."p(95)"' k6-results.json)
            HTTP_REQ_DURATION_P99=$(jq -r '.metrics.http_req_duration.values."p(99)"' k6-results.json)
            HTTP_REQ_FAILED_RATE=$(jq -r '.metrics.http_req_failed.values.rate' k6-results.json)
            ITERATIONS=$(jq -r '.metrics.iterations.values.count' k6-results.json)
            
            echo "| Metric | Value | Threshold |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|-----------|" >> $GITHUB_STEP_SUMMARY
            echo "| 95th Percentile Response Time | ${HTTP_REQ_DURATION_P95}ms | < 500ms |" >> $GITHUB_STEP_SUMMARY
            echo "| 99th Percentile Response Time | ${HTTP_REQ_DURATION_P99}ms | < 1000ms |" >> $GITHUB_STEP_SUMMARY
            ERROR_RATE_PCT=$(awk -v rate="$HTTP_REQ_FAILED_RATE" 'BEGIN {printf "%.1f%%", rate * 100}')
            echo "| Error Rate | ${ERROR_RATE_PCT} | < 5% |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Iterations | $ITERATIONS | - |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Check thresholds using awk
            if awk -v p95="$HTTP_REQ_DURATION_P95" 'BEGIN {exit !(p95 > 500)}'; then
              echo "âš ï¸ **Warning**: 95th percentile response time exceeds 500ms" >> $GITHUB_STEP_SUMMARY
            fi
            
            if awk -v rate="$HTTP_REQ_FAILED_RATE" 'BEGIN {exit !(rate > 0.05)}'; then
              echo "âŒ **Error**: Error rate exceeds 5%" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âš ï¸ No k6 results found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Stop backend server
        if: always()
        run: |
          if [ -f packages/backend/backend.pid ]; then
            kill $(cat packages/backend/backend.pid) || true
          fi

      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          if-no-files-found: warn
          retention-days: 90
          path: |
            k6-results.json
            k6-tests/

      - name: Comment PR with performance results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            if (!fs.existsSync('k6-results.json')) {
              console.log('No k6 results found');
              return;
            }
            
            const results = JSON.parse(fs.readFileSync('k6-results.json'));
            const metrics = results.metrics;
            
            const p95 = metrics.http_req_duration.values['p(95)'].toFixed(2);
            const p99 = metrics.http_req_duration.values['p(99)'].toFixed(2);
            const errorRate = (metrics.http_req_failed.values.rate * 100).toFixed(2);
            const iterations = metrics.iterations.values.count;
            
            let comment = '## âš¡ Performance Test Results\n\n';
            comment += '### Load Test Summary\n\n';
            comment += '| Metric | Value | Threshold | Status |\n';
            comment += '|--------|-------|-----------|--------|\n';
            comment += `| 95th Percentile | ${p95}ms | < 500ms | ${p95 < 500 ? 'âœ…' : 'âš ï¸'} |\n`;
            comment += `| 99th Percentile | ${p99}ms | < 1000ms | ${p99 < 1000 ? 'âœ…' : 'âš ï¸'} |\n`;
            comment += `| Error Rate | ${errorRate}% | < 5% | ${errorRate < 5 ? 'âœ…' : 'âŒ'} |\n`;
            comment += `| Total Requests | ${iterations} | - | â„¹ï¸ |\n\n`;
            
            comment += 'ðŸ“Š Full performance reports available in workflow artifacts.';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
        continue-on-error: true
